\chapter{Introduction}
\label{cha:introduction}
\epigraph{How do we get people to understand programming?}{Bret Victor}

The idea of learnable programming \cite{victor_learnable_2012} goes back to the early days of Smalltalk \cite{kay_early_1993}.
In his essay \emph{The Early History of Smalltalk}, Alan Kay looks back at the events that led to the creation of Smalltalk.
More importantly, he gives insight into the context of why Smalltalk turned out how it did.
Smalltalk was intended to be a learning environment for children, side-effects like its strong object orientation were merely artifacts of this main idea \cite{kay_early_1993}.
Objects, message passing and compositionality allowed people (not only children) using Smalltalk, to align their ways of thinking with the way their programs were structured.
Applying the conversational lens of programming environments (see Section~\ref{sec:conversational-lens}) to Smalltalk, one could argue that speaking the same language results in a shared mental model between the program and the programmer.
Or as Weinberg \cite{weinberg_psychology_1971} described the status quo (in 1971): "When we talk to our computers, unhappily, we are usually speaking in different tongues."
Unfortunately, not a lot of effort has been put into aligning those tongues over the last 50 years.

Programming environments that foster this style of communication are usually called live programming\cite{aguiar_live_2019, church_liveness_2010} or interactive programming \cite{czaplicki_interactive_2013, mccabe_towards_2023}.
Usually, such systems possess the following properties \cite{burg_1st_2013}:
\begin{description}
    \item[Live] They give the programmer immediate feedback, while the program is edited. This feedback can target its output, structure, or both.
    \item[Structured] Environments that are aware of a program's structure, understand and preserve this structure. They operate at the level of structure, not on raw text.
    \item[Tangible] Normally, program execution happens behind the scenes and provides little to no capabilities for live inspection. Tangible programming makes the execution transparent, tangible, and explorable.
    \item[Concrete] It is way easier for people to start with concrete examples and generalize later on.
\end{description}

Live programming systems lead to tighter feedback loops.
This outcome was described by \citeauthor{hancock_real-time_2003} \cite{hancock_real-time_2003} and illustrated in \cite{aguiar_live_2019} as shown in Figure~\ref{fig:bow-arrow} and Figure~\ref{fig:waterhose}.
%
\begin{figure}[h]
\centering
\includesvg[width=0.75\textwidth]{images/arrow-bow}
\caption{When trying to hit a target with a bow and arrow, one can only re-aim based on the previous shot. Feedback is provided only after the arrow reaches the target. Image source~\cite{aguiar_live_2019}.}
\label{fig:bow-arrow}
\end{figure}
%
There are multiple differences in trying to hit a target with a bow and arrow vs. with a hose.
The most obvious one is the constant stream of information that is provided by observing where the water hits the target in the second analogy.
But is this uninterrupted stream of information really the reason why it is easier to hit a target with a hose?
Hancock \cite{hancock_real-time_2003} argues that this is only a fraction of the reason, according to his interpretation the main difference is that the waterer \emph{never stops aiming}.
While the archer's actions consist of a series of distinct actions (while having to re-aim after each shot), the waterer does not have to "reload".
Hence the waterer does not need to switch contexts, while at the same time being supported by continuous feedback.
One can also visually perceive the shortened feedback loop between Figure~\ref{fig:bow-arrow} and Figure~\ref{fig:waterhose}.

\begin{figure}[h]
\centering
\includesvg[width=0.6\textwidth]{images/waterhose}
\caption{Aiming with a hose is much easier. Continuous feedback allows the person using the hose to constantly re-adapt to the target, without having to stop aiming at all. Image source~\cite{aguiar_live_2019}.}
\label{fig:waterhose}
\end{figure}

In contrast to the previously described problem of speaking the same tongue, several frameworks and programming tools are actively trying to shorten the feedback loop \cite{kubelka_road_2018}.
Web development tools in major browsers support direct page editing \addref, Vitest, a testing framework for JavaScript supports an instant watch mode \addref, all major web frameworks support hot-module reloading \addref, qwik lets developers click at components which takes them directly to the source code \addref. Redux allows developers to travel through their application state by providing time-traveling debugging \addref.
REPLs are kind of standard for newly developed languages \addref, Java and .NET support hot-reloading under certain circumstances \addref and Apple's Swift programming language supports live programming with interactive playgrounds \addref.
Although this list is by far not exhaustive and there is a clearly visible trend towards live programming, comparing tools used in industry to the properties of live programming, there is still a huge gap.
The next section portrays the concept of interactive programming in the broader context of software development, compared to "just" programming.

% \todo[inline,color=blue!40]{Maybe cross-reference to Psychology of Programming and explain that faster feedback fosters happiness.}



\section{Context}
\label{sec:context}
Continuing this idea of comparing programming and software development it becomes clear that programming is just a fraction of the whole software development process \cite{yang_phase_2008}.
A common view on the software development phases is \begin{enumerate*}[label=(\roman*)]
\item planning,
\item requirements analysis,
\item designing,
\item coding,
\item testing,
\item delivery and
\item maintenance
\end{enumerate*}
revealing that programming is indeed mainly part of coding and maintenance.
Although code-driven approaches targeting requirements analysis \addref, designing \addref, testing \addref, and delivery (continuous delivery) are becoming more and more popular, creating software is still more than coding.
People researching the psychology of programming came to the same conclusion \cite{curtis_psychology_1990}: "The fact that this field is usually referred to as the `psychology of programming' rather than the 'psychology of software development' reflects its primary orientation to the coding phenomena."
Successfully applying ideas of live programming to more aspects of the software development process than programming requires a closer look at them as well as their history.

% \todo[inline]{This feedback-loop metaphor can be applied to a specific developer, a team or even with customer-interaction.}
% \todo[inline]{In the introduction I did not differentiate between programming and software development, but it is a huge differentiation.}
% \todo[inline]{Explain the differences between psychology of programming and psychology of software development and what it has to do with requirements to code and idea to code.}

\subsection{Agile Software Development}
\label{sec:agile-movement}
The aforementioned feedback loops are applicable to a wide range of problems.
As such, software development or software engineering approaches might be considered.
Viewing their history through the lens of tightening feedback loops provides an additional perspective on why people adopted agile software development practices.

Working on projects, especially in teams, always follows a structure.
In software engineering, this structure is defined by software development methods.
When software engineering came up, practitioners adapted already existing project management methodologies to it, leading to highly rigid methods in the beginning \cite{misra_agile_2012}.
Those now called \emph{traditional software development methods} were focused on following well-defined plans and detailed documentation.
According to \citeauthor{misra_agile_2012}'s overview of the history of agile software development practices \cite{misra_agile_2012}, these rigid methods worked well for compilers and operating systems, but their heavy focus on well-defined plans was not flexible enough for developing small business applications as well as spreadsheets.
Although, being formalized in 2001 by \citeauthor{beck_manifesto_2001}, the origins of the agile software manifesto's ideas \cite{beck_manifesto_2001} date back to the early software development methods \cite{van_der_aalst_historical_2008}.
The core idea of the agile manifesto is defined as below:
%
\begin{quote}
    We are uncovering better ways of developing software by doing it and helping others do it.
    Through this work we have come to value:
    %
    \begin{itemize}
        \item \emph{Individuals and interactions} over processes and tools.
        \item \emph{Working software} over comprehensive documentation.
        \item \emph{Customer collaboration} over contract negotiation.
        \item \emph{Responding to change} over following a plan.
    \end{itemize}
    %
    That is, while there is value in the items on the right, we value the items on the left more.
\end{quote}
%

Alongside their manifesto, \citeauthor{beck_manifesto_2001} published twelve principles for developing software in an agile way.
Table~\ref{tab:agile-principles} lists these principles.
Based on the agile manifesto and the ideas of interactive programming, each of the principles is interpreted in how it might align with the fundamental idea of tightening the feedback loop.
If applicable, the interpretation also draws comparisons to how interactive programming might be beneficial for this specific principle.

\begin{block}
%\setlength{\tabcolsep}{10pt}     % separator between columns (standard = 6pt)
%\renewcommand{\arraystretch}{1.50} % vertical stretch factor (standard = 1.0)
%\caption{Applying the lens of tightening feedback loops through live programming to the agile principles \cite{beck_manifesto_2001}.}
%\label{tab:agile-principles}
%\centering
%\newcommand{\RR}{\rightskip=0pt plus1em \spaceskip=.3333em \xspaceskip=.5em\relax}
\renewcommand{\arraystretch}{1.30}
\small
%    \begin{english}
%    \begin{tabular}{@{}p{0.4\textwidth}p{0.55\textwidth}}
\begin{longtable}{@{}cp{0.35\textwidth}p{0.5\textwidth}@{}}
    % -------------------------- first header ----------------------------
    \caption{Applying the lens of tightening feedback loops through live programming to the agile principles \cite{beck_manifesto_2001}.} 
    \label{tab:agile-principles}																						 \\
    \toprule
    \# & Agile Principle & Interpretation \\
    \midrule
    \endfirsthead
    % ---------------------- subsequent headers ---------------------------
    \caption*{\textbf{Table \getcurrentlabel} (\emph{continued})}				 \\
    \toprule
    \# & Agile Principle & Interpretation \\
    \midrule
    \endhead
    % --------------------------------------------------------------------
    \toprule
    \# & Agile Principle & Interpretation \\
    \midrule
		\endhead
    (1) &
    Highest priority is given to satisfying the customer through early and continuous delivery of valuable software. &
    A clear example for tightening the feedback loop between the customer and development team.
    Continuously delivering software gives the customer the feeling of "being in the loop".
    \\
    (2) &
    Changing requirements are welcome, even late in development. Agile processes harness change for the customer’s competitive advantage. &
    According to \cite{van_der_aalst_historical_2008}, customers might not know their full problem space.
    Iterating on potential solutions, while close communication between development teams and customers is emphasized, leads to a co-exploration of the problem, as well as the solution space, enabled by tighter feedback loops.
    \\
    (3) &
    Working software is delivered frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale. &
    A perfect example for tightening the feedback loop between different versions of software.
    One should note the emphasis on "with a preference to the shorter timescale" which actively promotes shorter feedback loops.
    \\
    (4) &
    Business people and developers work together daily throughout the project. &
    Working together on a daily basis actively reduces the amount documentation overhead, hence shortening feedback loops.
    Although one has to be aware of the side-effects imposed by this (see \ref{sec:programming-as-theory-building} for an alternative take on the topic of documentation in software projects).
    \\
    (5) &
    Projects are built around motivated individuals.
    They are given the environment and support they need, and trusted to get the job done. &
    ---
    \\
    (6) &
    It is believed that the most efficient and effective method of conveying information to and within a development team is face-to-face conversation. &
    Again, face-to-face conversation is as short as a feedback loop can get.
    Applying interactive programming in a way that fosters face-to-face conversation about certain solutions would enhance this even more.
    \\
    (7) &
    It is believed that working software is the primary measure of progress.&
    ---
    \\
    (8) &
    It is believed that agile processes promote sustainable development.
    The sponsors, developers, and users should be able to maintain a constant pace indefinitely.&
    ---
    \\
    (9) &
    It is believed that continuous attention to technical excellence and good design enhances agility.&
    ---
    \\
    (10) &
    It is believed that simplicity – the art of maximizing the amount of work not done – is essential.&
    This principle can be approached in at least two ways.
    First, "maximizing the amount of work not done" could be applied to feedback loops in a way that no need for a feedback loop is even faster than a very tight one.
    Secondly, certain ideas of live programming could be utilized to prevent unnecessary features from being developed, thus contributing to simplicity.
    \\
    (11) &
    It is believed that the best architectures, requirements, and designs emerge from self-organizing teams.&
    The advantage of self-organizing teams could be caused by tighter feedback loops, leading to less feedback that gets mis-transferred.
    \\
    (12)&
    It is believed that success is achieved when at regular intervals the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly.&
    Retrospectives perfectly showcase what happens when tighter feedback loops (in this case about the internal workings of teams) are applied to software development.
    \\
    \bottomrule
\end{longtable}
\end{block}

\todo[inline]{Add --- note to the table.}

Summing up those principles, agile software development encourages lean development using iterative and evolutionary approaches.
Close collaboration between software development and business teams should lead to higher customer satisfaction by actually incorporating their (possibly changing) needs, instead of emphasizing processes and documentation.
Face-to-face communication, frequent deliveries, adapting and properly managing changing requirements, as well as having those organizational capabilities are necessary premises for implementing agile software development processes successfully \cite{misra_agile_2012}.
These original ideas were more and more commercialized with various frameworks being created based on the agile philosophy \cite{hohl_back_2018}.
According to \citeauthor{hohl_back_2018}, Scrum is often seen as the only agile practice.
Because managers and developers mainly apply frameworks, the initial diversity as well as the underlying principles of the agile manifesto get lost.


%\todo[inline]{somehow incorporate: Therefore, it is important for the business, and the development teams to work hand-in-hand throughout the entire duration of the project.}

Interestingly, already the waterfall method\addref, classified as a traditional software development method, defines feedback loops between successive stages of the software engineering process, introducing the stage of prototyping, intended for improving the phase of requirements analysis and design as early as possible.
Combining these feedback loops with the core idea of the spiral model\addref, namely it introducing the idea of an iterative approach in contrast to sequentially approaching the phases of software development, reveals the origins of agile practices \cite{misra_agile_2012}.
In the next section, we are gonna take a brief look on the topic of prototyping and how agile ideas have been applied to different types of prototyping.


\subsection{Prototyping}
In his essay \citetitle{gladden_stop_1982} about the shortcomings of the waterfall model, \citeauthor{gladden_stop_1982} argues that sequential software development processes leads to missed schedules and the creation of unsuccessful products in a sense that the produced software \begin{enumerate*}[label=(\roman*)]
\item does not perform the function intended, or
\item does not satisfy the customer's needs
\end{enumerate*}
and calls for a different form of collaboration between the involved parties \cite{gladden_stop_1982}.
His argumentation consists of the inherent complexity of communicating requirements between different parties, the huge impact of changing requirements and the elapsed time between specifying requirements and actually seeing their outcome.
Introducing the \emph{Non-Cyclical (Hollywood) Model}, he proposes that: "Nothing conveys more meaning or serves to congeal a system concept better than the system itself" \cite{gladden_stop_1982}.
Instead of defining (textual) requirements, customers should present their objectives and work together with the development team on agreeing upon them.
One of his described techniques for achieving objectives is \emph{rapid prototyping}.
For properly understanding prototyping it might make sense to take a look at the etymological origin of said word: \emph{prototype} is analyzable as \texttt{proto-} and \texttt{type}.
The word's origin goes back to Ancient Greek \emph{\textgreek{πρωτότυπος}} (original; prototype), with the conjunction of \emph{\textgreek{πρῶτος}}, (first; earliest) and \emph{\textgreek{τῠ́πος}} (pressing; sort; type).

This is mainly how the concept of a prototype is understood in software development \cite{budde_what_1992}, with slight differences in interpretation.
Although these interpretation differences are not big, their effects do not really align with the original concept of a prototype.
We will refer back to the etymological origin of the word \meph{prototype} to depict some of those contradictions.

Prototypes are used to create a shared understanding between developers, users, and management \cite{budde_what_1992}.
They are used to identify difficulties, clarify problems and misunderstandings, and help in making design decisions.
If necessary, they are complemented with written system specifications.
According to \cite{budde_what_1992} a prototype that "is used for more than experimental testing of an idea for illustrative purposes, but rather is employed in the core of the application" is known as a pilot system.
A pilot system requires a much more elaborate design than a prototype.
Applying the etymological perspective, a "first type" of some program does not have to be as stable or as mature as if it is part of the finished product.
Although \citeauthor{budde_what_1992} clearly distinguish prototypes from pilot systems, this looks very different in practice.
They already present this contradiction in their article when explaining different goals of prototyping \cite{budde_what_1992}.
\begin{enumerate*}[label=(\roman*)]
\item \emph{Exploratory Prototyping} is used when the problem to solve is unclear or underspecified. In this case, prototyping is used to evaluate different solutions and clarify requirements.
\item \emph{Experimental Prototyping} can be seen as a technical feasibility study. Developers experiment with the help of prototypes to find out whether existing requirements can be fulfilled.
\item \emph{Evolutionary Prototyping} emphasizes the nominalized verb \emph{prototyping} over the noun \emph{prototype}. The focus lies on the process of creating one prototype after another, leading to prototypes being converted to pilot systems, being converted to the actual product. This interpretation contradicts the ancient Greek understanding of the word prototype. Visualizing processes involving the progress of time is easier when shown graphically, thus Figure~\ref{fig:throw-away-prototyping} and Figure~\ref{fig:evolutionary-prototyping} show these differences.
\end{enumerate*}

Matching the meaning of the word prototype, throw-away prototyping (as shown in Figure~\ref{fig:throw-away-prototyping}) treats prototypes as artifacts from ideation phases.
The source code of these prototypes is \emph{not} reused later when the application itself is developed.
Knowing that the source code will not be reused creates a mindset where software engineers focus on creating the functionality that should be prototyped and do not focus on code style and maintainability.
Sketching and prototyping are usually two different things.
Sketching is focused on the user interface and user experience and does not concern the technical implementation of a piece of software.
The phases (depicted as arrows) in Figure~\ref{fig:throw-away-prototyping} highlight that developing features starts after their respective sketching or prototyping phases.
%
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/throw-away-prototyping}
\caption{Throw-away prototyping and sketching: prototypes help gather early feedback before starting to develop the actual feature. Image source~\cite{mourzenko_answer_2014}.}
\label{fig:throw-away-prototyping}
\end{figure}
%
In contrast to throw-away prototyping, the concept of evolutionary prototyping (as shown in Figure~\ref{fig:evolutionary-prototyping}) incorporates customer feedback iteratively and incrementally over the whole process of product development.
As described in \cite{mourzenko_answer_2014}, code style, maintainability, design patterns, and testing count from the beginning of development, because starting with an early prototype the actual product is an evolution of it.
As depicted in Figure~\ref{fig:evolutionary-prototyping}, based on feedback and requirements new features are added as well as existing ones are adapted or removed, leading to the final product.
This evolutionary approach clearly contradicts the original definition of prototype being a \emph{first type}.
Furthermore, if a project is started with the premise of developing a prototype, developers should write code that adheres to the philosophy of prototyping, which intentionally excludes proper code style as well as software architecture.
If such a prototype should then be evolved into an evolutionary one, this basis is missing, making it exponentially harder to properly introduce a solid, scalable architecture that supports the requirements of a long-living product.
%
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/evolutionary-prototyping.png}
\caption{Evolutionary prototyping: features are aggregated to the prototype to build the final product. Image source~\cite{mourzenko_answer_2014}.}
\label{fig:evolutionary-prototyping}
\end{figure}

\subsubsection{Wizard of Oz Prototyping}
\label{subsub:wizard-of-oz-prototyping}
One other interesting type of prototyping for the context of this thesis might be \emph{Wizard of Oz Prototyping} \cite{dow_wizard_2005}.
The Wizard of Oz Methodology has its origins in human-computer interaction research, specifically in the area of "exploring user interfaces for pervasive, ubiquitous,
or mixed-reality systems that combine complex sensing and intelligent control logic" \cite{dow_wizard_2005}.
It would take an immense amount of resources to create such an interface, but if one is able to draw a sensible line between the user interface and its actual implementation, this implementation can be simulated by humans.
This enables the system to be tested, without the need for it to be implemented, which again aligns with the original meaning of the word prototype.
The etymological origin of the Wizard of Oz methodology can be traced back to the "American children's book \emph{The Wonderful Wizard of Oz} by Frank Baum, in which the characters meet a giant head, that appears to be a powerful wizard, only to learn that it’s just an ordinary man pulling levers behind a screen" \cite{ramaswamy_wizard_2022}.

%\todo[inline,color=blue!40]{Maybe look into Rapid Application Development and its approach on Prototyping}
%\todo[inline]{Bring the concept of tactical programming vs. strategic programming into play (based on Osterhout as described in my Psychology BA)}
%\todo[inline]{Mention that prototypes get released to production (Tesla, Spotify, Apple) and that customers do the testing.}
%\todo[inline,color=blue!40]{Maybe bring in a little bit of capitalism criticism in the form of market fit vs. high-quality products, just show the contradiction.}


%\subsection[Interactive Programming]{Interactive Programming \protect{\estimatedpagecount{.5}}}
%\todo[inline]{Bridge the gap between prototyping and interactive/live programming as described in the introduction. Mention how this might align with agile methodologies, the psychology of programming and customer-centered approaches.}


\section{Problem Statement}
As stated in \citetitle{anonymous_what_1967}, programming is a communication process \cite{anonymous_what_1967}.
Even if programming is not seen as a mainly human-centered activity, translating thoughts into a language understood by machines is a form of communication, namely \emph{Human Computer Interaction} (HCI) \cite{myers_past_2009}.
As already described in Section~\ref{sec:context} analyzing the broader context of programming, namely software development emphasizes the relevance of communication as well.
Whether they are called requirements or objects, the users' needs have to be identified and translated into working code.
Agile development practices foster the creation of successful applications by bringing stakeholders together and allowing them to iterate on proposed solutions.
Prototyping is one such tool that enables the co-creation of software, but if it is applied incorrectly (often times because of tight schedules) it leads to brittle and unstable products.
Live-Programming can also be interpreted as a tool to enable the co-creation of software, but it is mainly aimed at helping a specific developer understand how and why some code works.
One could argue now, that programming tools (frameworks, environments, languages, ...) are not optimized for the agile co-creation of software while still emphasizing technical scalability and longetivity.
This section is aimed at clarifying this problem statement, as well as provide deeper insights into the social as well as psychological insights of developing software.

%As stated in \textcite{curtis_psychology_1990} mainly organizational processes characterize software development.

\subsection{Programming as Complex Problem Solving}
Complex problem solving is a research discipline in psychology that is concerned with how humans solve complex problems.
There are a lot of arguments about the definition of \emph{a complex problem}, with an overview presented in \cite{dorner_complex_2017}.
As defined by \citeauthor{funke_complex_2012} a complex problem is defined by
\begin{enumerate*}[label=(\roman*)]
\item its immense amount of involved variables,
\item a lot of dependencies between those variables,
\item the dynamics of the situation
\item (partial) intransparency of those variables and their connections, and
\item \emph{polytely} (the greek term for “many goals”), resulting in goal conflicts \cite{funke_complex_2012}.
\end{enumerate*}
Complex problems can further be divided into the categories well-defined and ill-defined.
\emph{Well-defined problems} do have a fixed problem space as well as a fixed solution space.
Their problem state and goal state are both well known.
An example for a well-defined problem is the assignment to write a program that prints some text $n$ times.
As a solution one could either copy and paste the print-statement $n$ times or create a loop that prints said text $n$ times.
\emph{Ill-defined problems} do not have a clear problem definition, desired goal and there is no obvious and clear way of reaching the goal.
Most programming problems that are more complex than printing some text $n$ times are ill-defined problems.
It becomes even more clear, if one takes a more holistic view at software development, compared to "just" programming.
Usually a group of people has to create some product that fits some needs, resulting in a partially open problem as well as solution space with many potential ways of getting to this solution.

Multiple studies have been conducted on the programming part of complex problem solving \cite{lawan_what_2019, gibson_software_2005, robertson_role_2008, taheri_evaluating_2015}, whereas the research area of complex problem solving applied to actual software development was researched quire sparsely \cite{wingo_using_2015}.
\citeauthor{curtis_psychology_1990} pointed this out as early as 1990 \cite{curtis_psychology_1990}: "The fact that this field is usually referred to as the `psychology of programming' rather than the `psychology of software development' reflects its primary orientation to the coding phenomena."
This research problem gets multiplied by the fact that conducting experimental research regarding complex problem solving is hard to closely align to reality.
Although a lot of variables can be introduced as well as controlled in a lab situation, complex problems are also defined by the dynamics of their situation, complicating experimental designs and making their results less applicable to real-world scenarios \cite{lawan_what_2019}.


\subsubsection{Top-Down vs. Bottom-Up}
Top-down and bottom-up are methods to approach problems.
Both approaches describe how to handle the de-composition as well as the composition of sub-problems.
Especially the before mentioned \emph{complex problems} need strategies for solving them.

If a problem is defined quite openly and broad, applying the top-down approach proved to be fitting \cite{kung_comparing_2013}.

As described by \citeauthor{kung_comparing_2013} \cite{kung_comparing_2013}, "Adoption of a top-down approach will generally start with a set of high-level requirements, such as a narrative."
Thus, problems that benefit from approaching them in a top-down manner, do usually have a an open and broad problem definition, hence their problem as well as their solution scope still need to be explored.
Figure~\ref{fig:top-down} depicts a visual representation of the top-down approach showing how the problem and solution space are explored starting from the top.
The more \emph{ill-defined} a problem presents itself, the better the top-down approach works.
%
\begin{figure}[h]
\centering
\hspace*{0.15\linewidth}
\includesvg[width=0.75\textwidth]{images/top-down}
\caption{Approaching a problem in a top-down way. The intensity of a rectangle's color conveys information about how well the (sub-)problem and solution space are already explored. Exploring the problem starts at the top and it is divided into smaller sub-problems.}
\label{fig:top-down}
\end{figure}
%
The opposite approach is depicted in Figure~\cref{fig:bottom-up}.
One needs to already know what the "bottom" of the problem under investigation is to apply the bottom-up method.
As described by \citeauthor{jones_answer_2011} \cite{jones_answer_2011}: "To use the bottom-up method you need to be able to efficiently determine what the "bottom" is, which usually means you need a heavily constrained problem space."
Already existing partial solutions are composed in such a way that they solve the whole problem.
\emph{Well-defined} problems can usually be solved quite well using the bottom-up method, because if the problem space is known and solutions for these sub-problems exist, they "just" need to be assembled.
%
\begin{figure}[h]
\centering
\hspace*{0.15\linewidth}
\includesvg[width=0.75\textwidth]{images/bottom-up}
\caption{Approaching a problem in a bottom-up way. The intensity of a rectangle's color conveys information about how well the (sub-)problem and solution space are already explored. Solving the problem starts at the bottom, where already existing solutions are composed together, so that the whole problem can be solved.}
\label{fig:bottom-up}
\end{figure}
%
Although we just introduced a clear distinction between top-down and bottom-up approaches, in reality (regarding programming as well as software engineering) a combination of both is used.
Requirements are seleten so clear that developers immediately know how to approach them bottom-up, but already existing solutions for cross-functional requirements like logging or authentication might be well known and can be directly applied.
This leads to a mixture of top-down and bottom-up usage, where parts of the solution have to be explored with a general concept in mind, whereas other parts of the problem can already be solved with existing solutions.
Applying this insight to progamming imposes the interesting question of how to combine both approaches for keeping track of what is already solved and what not.
Keeping track of something can be seen as an act of conversation, \citeauthor{mccabe_towards_2023} applied this lens to modern development environments, the next chapter sums up their ideas and explains the motivation behind.


\cite{kung_comparing_2013}
Top-down approaches stress an initial focus on knowledge of higher-level constructs, such as identification of populations and collections of things and entity types, membership rules, and relationships between such populations. Adoption of a top-down approach will generally start with a set of high-level requirements, such as a narrative. These requirements start a process of identifying the types of things needed to represent data with as well as the attributes of those things, which may become attributes in tables.

top-down: the analyst attempts to construct a domain ontology

In many cases, an initial conceptual data model is drafted that does not include all data attributes.

In contrast, bottom-up approaches view database design as proceeding from an initial analysis of lower-level conceptual units, such as attributes and functional dependencies and then moving towards an acceptable logical data model through logical groupings of associated attributes.

synthesis in this context relates to its philosophical meaning: “logical deduction”

Choice of technique would depend on “several factors such as the nature of the problem domain, previous modeling efforts, and personal preference.”

\cite{jones_answer_2011}
To use the bottom up method you need to be able to efficiently determine what the "bottom" is, which usually means you need a heavily constrained problem space. If you know what the lowest level calculations are going to be and the dependency order going upward, it makes sense to iteratively do them in the proper order and store those results. Factorials, naive Fibonacci and the Euler recurrence relation for partitions are all good examples of problems suited to this approach.

Some problems don't have an easily determined bottom or dependency order for the calculations. Chess positions evaluations, for example, are usefully memoized by position, with the evaluation score stored so it need not be recalculated. Positions can recur at multiple levels of the search tree due to move transposition and repetition so saving evaluation results is worthwhile. But there's no way to know what the positions at the lowest levels of the tree are going to be without recursively descending (and taking into account intermediate pruning) so top down is really the only feasible approach.


\todo[inline]{Explain top down and bottom up processes and how they problem solving applies to it via functional (de-)composition.}
\todo[inline]{"To use the bottom up method you need to be able to efficiently determine what the "bottom" is, which usually means you need a heavily constrained problem space."}


\subsubsection{Conversational Lens regarding Complex Problem Solving in Development}
\label{sec:conversational-lens}
Modern development environments and analysis tools point out various possible bugs and vulnerabilities based on static code analysis.
As research has shown, those results are commonly not respected \cite{mccabe_towards_2023}.
Alan T. McCabe has analyzed why they are not used as much as they could be, with the most prominent reasons being:
\begin{enumerate*}[label=(\roman*)]
\item false-positives, leading to a lot of noise;
\item poor understandability, causing frustration and non motivation to dig into these reports; and
\item a lack of integration into the developer's workflow, forcing them to switch contexts and drop out of being in the flow.
\end{enumerate*}
Based on these discoveries \citeauthor{mccabe_towards_2023} approached the improvement of development tools through the conversational lens.
Drawing from observations around the mechanics of human conversations, they try to apply human-like conversation approaches to the code analysis tools.
However it is of high importance, that they do not want to anthropomorphize those tools, rather they wan't to align interactions in such a way that more accurate mental models can be built up.
By targeting observability of compilation processes and "framing an interaction as a `conversation' between a human and their development environment" \cite{mccabe_towards_2023} the compiler's \emph{thought process} can be externalized and understood by the developer in a similar way as misunderstandings can be clarified when when talking with another human being.

Edwin Brady shares a similar view on compilers, he imagines the compiler as the "lab assistant", in a way that the compiler should take part in a pair programming exercise, helping developers accomplish their goals.
An example of how this works is shown in Section~\ref{sec:introducing-hole-driven-development}.


\subsubsection{Programming as Theory Building}
\label{sec:programming-as-theory-building}
Applying the conversational lens to the greater context of developing software in teams and organizations leads to Peter Naur's influential paper \citetitle{naur_programming_1985}.
Bridging the gap between the psychology of programming and psychology of software development, the findings of this paper constitute a major part of this thesis' hypothesis, hence there is a separate section dedicated to it.

Peter Naur argues that programming is not an activity of text production, rather it is an activity of creating a shared understanding while the activity of text production itself should be understood as a series of program modifications.
He highlights the importance of a correct understanding of programming like the following: "If our understanding is inappropriate, we will misunderstand the difficulties that arise in the activity and our attempts to overcome them will give rise to conflicts and frustrations. \cite{naur_programming_1985}"
After clarifying that he uses the term \emph{programming} to denote the whole activity of design and implementation (at the beginning of Chapter~\ref{cha:introduction} we differentiated between \emph{programming} and \emph{software development} with the latter one being synonymous to Naur's understanding) he introduces his Theory Building View based on Ryle's definition of the word \emph{theory}\addref.
The possession of a theory is not defined by any particular knowledge of facts, but by being able to do things, accompanied by explanations, justifications and responses to queries about it \cite{barn_revisiting_2011}.

Building upon this definition, Naur continues to argue that for bringing new programmers onto a team, they have to work in close contact with programmers who already possess the theory.
Because there particular sequence of actions (method) that is underlying the process of theory building, this theory cannot be documented via textual artifacts.
With the essence of the program, its theory, being inextricably bound to human beings, the role of programmers changes from one that produces source code and documentation (an easily replaceable one) to one that possesses the vital theory about those artifacts.
Based on these insights, Naur argues that the assumption that software is easy and cheap to modify is a fallacy.
Because it is not the source code of a program that has to be modified, but rather the theory (shared understanding) modification of software is e.g. comparable to the modification of buildings, which are known to be expensive and in fact, sometimes it is economically preferable to demolish the existing building and re-build it as a whole.
Arguing that creating highly flexible programs diminishes the need for modification is the next fallacy, because the increase in complexity introduced by flexibility, leads to substantial costs already upfront.
Accordign to Naur, because of programming being an act of theory building, we should emphasize ways of improving the sharing of understanding, hence the formation of theories.

\subsubsection{Applying Philosophy to the Theory Building View}

In their contemporary philosophical analysis of agile software development, \citeauthor{northover_agile_2007} applied Karl Popper's philosophy of \emph{evolutionary epistemology} to software development \cite{northover_agile_2007}.
According to Popper\addref, all advances in knowledge follow the following model:

\[P_1 \rightarrow TS \rightarrow EE \rightarrow P_2\]

$P_1$ is the initial problem, $TS$ is the proposed solution, $EE$ is the process of error elimination applied to $TS$, and $T_2$ the resulting solution containing new problems \addref.
Applying this model to the context of iterative software development, \citeauthor{northover_agile_2007} interpret it as the following: $P_1$ is the initially identified subset of requirements, $TS$ corresponds to the solution proposed by the developer -- "the developer's `theory'" \cite{northover_agile_2007}, $EE$ are the testers' attempts on eliminating errors by creating test cases and $P_2$ corresponds to a tested subset of the software.

With Naur's theory building view in mind, one could argue that by interpreting the model in the way \citeauthor{northover_agile_2007} did, such that developers are not included in the $EE$ stage, hardly allows them to improve their theory of the system.
Only by including them into the error elimination phase ($EE$) enables them to refine and adapt their theories of the system.
This interpretation is continued in \ref{sec:hypothesis}.


\subsection{Cognitive Load}

\cite{seemann_code_2021}
A fundamental problem with software development is that there's a lot going on. Our brains aren't good at keeping track of many things at the same time.
We also have a tendency to skip doing things that don't seem important right now.
The problem isn't that you don't know how to do a thing; it's that you forget to do it, even though you know that you ought to.
This problem isn't isolated to programming. Pilots suffer from it, and they invented a simple solution to the problem: \emph{checklists}.
It is important to understand that checklists are supposed to enable, support and liberate practitioners.
Checklists are not intended to constrain you.
A checklist is just an aid to memory, it exists to help you remember to perform trivial, but important actions, such as washing your hands before surgery.

Human short-term memory can hold from four to seven pieces of information. \cite{shaw_memory_2016}

Any non-trivial piece of software is going to have much more going on, so you need to decompose and comparmentalise the code structure unto small chunks that each fit in your brain.
As Kent Beck puts it:
"The goal of software design is to create chunks or slices that fit into a human mind. The software keeps growing, but the human mind maxes out, so we have to keep chunking and slicing differently if we want to keep making changes."
How to do that is the most important isicpline of software engineering.

\cite{ormerod_human_1990}
Since the number of processes involved in programming is large, attentional and memory resources must be divided up amongst competing processes, thereby limiting performance.
Resource theories may explain the source of some programming errors.
For example, insufficient short-term memory resources have been suggested to account for errors made by novice Lisp programmers
A resource account of programming errors implies that performance can be improved if the resource requirements of a task are decreased.

\cite{digiano_learning_nodate}
In the workplace and in the classroom, there is an increasi ng need for harnessing the collective intelligence of groups to learn faster, envision new possibilities, and reveal latent knowledge.
Our research focuses on employing the Post -It metaphor to support emergent collaborative activity across multiple connected co-located machines.
Properties that make Po st-Its desirable for flexible collaborative work include that they are:
(Re)arrangable. Post -Its can be positioned and repositioned to convey meaning.
Unique. As physical artifacts, Post -Its cannot be in more than one place at a time, suggesting turn -taking in editing or changing.
Lastly, there is the awkwardness of archiving or publishing the results of a Post-It activity.

\cite{dove_grouping_2018}
results in them typically being used to represent a single idea.
Finally, individual Post-It notes are of little value in themselves and, can therefore be easily discarded if the idea they contain is no longer considered important.
As such, externalisations must evolve as complex problems develop and situations are transformed, and therefore be both expressive (mutable) and associative (combinable)


\section{Tackling Complexity}
\todo[inline]{Create the interactive manifesto as the basis for researching incomplete programs, programs in agile are consistently in an incomplete state (refer to Seeman for this) and as such, we should not lie to ourselves, that it is not like that, rather embrace this and strive for solutions that help us developing incomplete programs.}
\todo[inline]{Transition to the hypothesis section of this paper, because of it being a Proof of Concept}

\subsection{About Todo-Comments}
\todo[inline]{Start with an introduction on scientific results regarding Todo comments}
\todo[inline]{Do a short qualitative analysis regarding the various stackexchange posts on Todo-Comments}
\todo[inline,color=blue!40]{If I manage to find, I intend to include some statistics on Todo-Comments}
% - \url{https://www.petermorlion.com/the-lifetime-of-todo-comments-the-results/}
% - Tickgit
\todo[inline,color=blue!40]{Maybe try to group and order these into separate categories/quantitites, or report them by stackexchange question/discussion}
% - https://softwareengineering.stackexchange.com/questions/175719/can-notes-to-dos-in-code-comments-sent-to-code-reviews-result-in-an-effective-re
% - \url{https://softwareengineering.stackexchange.com/questions/323498/why-is-having-a-notimplementedexception-a-good-thing#comment687389_323498}
% - https://softwareengineering.stackexchange.com/questions/125320/do-todo-comments-make-sense
% - https://stackoverflow.com/questions/1989177/how-to-manage-todo-programming-stuff
% - https://stackoverflow.com/questions/16913055/how-can-i-mark-to-do-comments-in-xcode
% - https://stackoverflow.com/questions/335378/how-do-you-flag-code-so-that-you-can-come-back-later-and-work-on-it
\todo[inline,color=green!40]{relevant literature: \cite{nie_natural_2018, ying_source_2005, nie_framework_2019, sridhara_automatically_2016, storey_todo_2008, storey_how_2009}}


Do TODO comments make sense? \url{https://softwareengineering.stackexchange.com/questions/125320/do-todo-comments-make-sense}

+ I tend to use // todo comments for things that have to happen, but I can't do immediately.
o I use them liberally when I haven't completely fleshed out the implementation of a module but the contract is satisfactory for me (or others) to continue development on another related piece.
o I search for them
o Yep, given a listing in your IDE, they are helpful. I would say they're of very limited use otherwise, since the codebase may be enormous.
o In my industry, developers are encouraged to make JIRA (or etc) entries instead of todo comments because not everybody gets a chance to see the // todo entries. But sometimes in large projects a custom attribute gets defined along the lines of:
o In my experience it depends. The main factor is whether or not the team is disciplined enough to follow up on these "little" comments. If they do then yes they make sense. If they don't then these comments are just a waste of time and you may want to look into other options, e.g. story cards.
- I usually encounter TODO's written by someone else that look like this: //TODO make this code work
- they tend to rot over time.

about recalling them:
The key point is to use consistent tags such as TODO or FIXME so that they can be easily found with simple text search.
Modern IDEs recognize the TODO comments and they are as such visible in their own panel/window/tab, so they are theoretically not lost !!! think about online VCS, GitHub, PRs

about tags:
As it is written in Wikipedia's article on comments, including the date and owner of the TODO is considered to be a good practice.
I think the date and owner of the TODO is just noise. That's what version control (and the blame feature) are for (if you really need the information).

about time:
To be useful they should provide a means to bookmark your code for the (very) near future so that you can get back in the proper state of mind faster. In other words, you place them in your code only to remove them ASAP.


Does anybody still use TODO for writing code later on? \url{https://softwareengineering.stackexchange.com/questions/316797/does-anybody-still-use-todo-for-writing-code-later-on}

o If you are into TDD, I suggest you write up a test which will fail until the functionality gets implemented.

Use of NotImplementedException \url{https://softwareengineering.stackexchange.com/questions/128389/use-of-notimplementedexception}

about IDE dependence:
o I would recommend using the NotImplementedException combined with TODO comments, that way you combine GUI help (with the tasks in VS) and program safety.
o If you use Resharper, it shows NotImplementedExceptions in the same way as TODO comments. I think that's a nice feature.

How to handle a TODO in a pull request? \url{https://softwareengineering.stackexchange.com/questions/362286/how-to-handle-a-todo-in-a-pull-request}

o Write it down in your DoD that TODO, FIXME, or similar tags should be avoided.
o Use a static code analysis tool such as SonarQube to automatically mark the build unstable.
o Temporarily allow them if, and only if, there is a corresponding ticket in your issue tracker. Then, the code may look like TODO [ID-123] Description ...

Personally, I think TODOs are sometimes reasonable, but one should not use them excessively. Taken from Robert C. Martin's "Clean Code: A Handbook of Agile Software Craftsmanship" (p. 59):
TODOs are jobs that the programmer thinks should be done, but for some reason can't do at the moment. It might be a reminder to delete a deprecated feature or a plea for someone else to look at a problem. It might be a request for someone else to think of a better name or a reminder to make a change that is dependent on a planned event. Whatever else a TODO might be, it is not an excuse to leave bad code in the system.

How do you flag code so that you can come back later and work on it? \url{https://stackoverflow.com/questions/335378/how-do-you-flag-code-so-that-you-can-come-back-later-and-work-on-it}
o TODO comes up with a nasty brown background in vim - visual code smells
o Mark them with // TODO, // HACK or other comment tokens that will show up in the task pane in Visual Studio.
o Also, I add bookmarks in Visual Studio on lines that are incomplete.
o I favor Jon T's general strategy, but I usually do it by just plain breaking the code temporarily - I often insert a deliberately undefined method reference and let the compiler remind me about what I need to get back to:
- In particular, I haven't seen TODO comments ever decrease in quantity in any meaningful way. If I didn't have time to do it when I wrote the comment, I don't know why I'd have time later.
+ I have a ToDo(msg) macro that expands into constructing a static object at local scope whose constructor outputs a log message. That way, the first time I execute unfinished code, I get a reminder in my log output that tells me that I can defer the task no longer.


\subsection{Introducing Hole-Driven Development}
\label{sec:introducing-hole-driven-development}
\todo[inline]{Start with the \emph{Fill in the Blank Exercise} analogy, then continue with an example}
\todo[inline]{Quickly show the Idris example, but mainly reference the related work section}

The term \emph{Hole-Driven Development} is not yet scientifically defined, but based on other programming concepts like \emph{Type-Driven Development} \cite{brady_type-driven_2017} or \emph{Test-Driven Development} \cite{mccracken_digital_1957}.
The main idea stems from the \emph{Agda} programming language\footnote{\url{https://wiki.portal.chalmers.se/agda/pmwiki.php}} where \emph{holes} are called \emph{goals}.
Apart from Agda, other languages such as Haskell\footnote{\url{https://www.haskell.org/}} and Idris\footnote{\url{https://www.idris-lang.org/}} feature the concept of holes.
The common properties of those languages is their functional nature and a very sophisticated type system.
These two aspects lay the foundation for Hole-Driven Development as currently understood.

Simply said, a \emph{hole} declares a missing part in an application.
One can imagine the holes as the blanks in a fill-in-the-blanks exercise.
By deliberately omitting certain expressions in programs, more information about these expressions can be provided by the compiler, which can aid the programmer in properly filling them.
The example in Listing~\ref{fig:idris-program-hole} was created by \citeauthor{brady_type-driven_2017} for his dependently typed functional programming language Idris \cite{brady_type-driven_2017}.
Idris supports the concept of holes by prefixing expressions with the questionmark character (\texttt{?}), which turns these expressions into holes.
In Line \verb|2| of Listing~\ref{fig:idris-program-hole} the function \verb|main| is defined that should print something (using the standard library function \verb|putStrLn|) to the console.
The ``hole'' part of this program is \verb|?greeting| at line \ref{lst:idris-hole-definition}.
The hole expression signals the Idris compiler that something in this program is missing that the developer didn't specify yet.
The syntax using a question mark can be understood as formulating a question to the compiler.

\begin{GenericCode}
main : IO ()
main = putStrLn ?greeting/+\label{lst:idris-hole-definition}+/
\caption{Hole-Driven Development in Idris}
\label{fig:idris-program-hole}
\end{GenericCode}

When trying to evaluate the program depicted in Listing~\ref{fig:idris-program-hole}, the Idris compiler will list all holes, as shown in Listing~\ref{fig:idris-compiler-holes}, in this case \texttt{Main.greeting} is shown at line \ref{lst:idris-holes-listing}.
For interacting with the compiler in this way, Edwin Brady coined the phrase ``the compiler as your lab assistant'' \cite{brady_type-driven_2017}.
His imagination of a compiler is one of a counterpart one interacts or pair-programs with.
One tells the compiler all the things that are currently in one's mind and as a reward one can ask questions, which the compiler will try to answer, based on the knowledge already provided.
Referring back to Section~\ref{sec:conversational-lens}, this conversational act resembles the human way of interacting with the compiler.
One can then continue to ask about the holes and their types by querying the holes' names in the Idris REPL.
The result of such an operation is shown in line \ref{lst:idris-holes-types}, which indicates that the hole \texttt{?greeting} has to be filled with an expression of type \texttt{String}.

\begin{GenericCode}[numbers=none]
Type checking ./Hello.idr
Holes: Main.greeting/+\label{lst:idris-holes-listing}+/

*Hello> greeting
?greeting : String/+\label{lst:idris-holes-types}+/
\caption{Idris Compiler analyzing Holes}
\label{fig:idris-compiler-holes}
\end{GenericCode}

This process helps the developer, filling in those holes by gradually combining the act of creating holes, inspecting information about them and then refining them.
As Brady put it into words: "Holes allow you to develop programs \emph{incrementally}, writing the parts you know and asking the machine to help you [...]'' \cite[pp. 21]{brady_type-driven_2017}.
The next section will combine the ideas presented in the introduction up to now, leading to this thesis' hypothesis.

\section{Hypothesis, Research Question and Methodology}
\todo[inline]{Lay out the process of approaching this thesis}
\todo[inline]{It mainly consists of deducing the requirements based on literature (reference the according chapter in related work), and validating the results according to the already supported concepts of Hole-Driven Development}
\todo[inline]{\emph{This work represents a proof of concept for applying the concept of hole-driven development to general-purpose programming languages, in this case \CS.}}
\todo[inline]{\emph{Which aspects of existing Hole Implementations can be transferred to general-purpose (mainstream) programming languages? With the requirements being laid in Sec 2.4 out after analyzing those in Sec 2.}}
